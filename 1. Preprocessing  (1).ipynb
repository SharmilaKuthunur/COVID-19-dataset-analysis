{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing\n",
    "\n",
    "This section contains the following: \n",
    "\n",
    "    1.1. Overview of the dataset\n",
    "    1.2. Addressing missing values\n",
    "    1.3. Filtering required columns\n",
    "    1.4. Adding required columns\n",
    "    1.5. Downloading preprocessing dataset as a CSV file\n",
    "    1.6. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the downloaded dataset *Analysis* is read into a Pandas DataFrame *preprocessing_dataset*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_dataset = pd.read_csv(\"C:\\\\Users\\\\Sharmila\\\\Desktop\\\\time-series-19-covid-combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Country/Region Province/State   Lat  Long  Confirmed  \\\n",
      "0      2020-01-22    Afghanistan            NaN  33.0  65.0        0.0   \n",
      "1      2020-01-23    Afghanistan            NaN  33.0  65.0        0.0   \n",
      "2      2020-01-24    Afghanistan            NaN  33.0  65.0        0.0   \n",
      "3      2020-01-25    Afghanistan            NaN  33.0  65.0        0.0   \n",
      "4      2020-01-26    Afghanistan            NaN  33.0  65.0        0.0   \n",
      "...           ...            ...            ...   ...   ...        ...   \n",
      "23491  2020-04-15       Zimbabwe            NaN -20.0  30.0       23.0   \n",
      "23492  2020-04-16       Zimbabwe            NaN -20.0  30.0       23.0   \n",
      "23493  2020-04-17       Zimbabwe            NaN -20.0  30.0       24.0   \n",
      "23494  2020-04-18       Zimbabwe            NaN -20.0  30.0       25.0   \n",
      "23495  2020-04-19       Zimbabwe            NaN -20.0  30.0       25.0   \n",
      "\n",
      "       Recovered  Deaths  \n",
      "0            0.0     0.0  \n",
      "1            0.0     0.0  \n",
      "2            0.0     0.0  \n",
      "3            0.0     0.0  \n",
      "4            0.0     0.0  \n",
      "...          ...     ...  \n",
      "23491        1.0     3.0  \n",
      "23492        1.0     3.0  \n",
      "23493        2.0     3.0  \n",
      "23494        2.0     3.0  \n",
      "23495        2.0     3.0  \n",
      "\n",
      "[23496 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=black>1.1. Overview of the Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns in the dataset, their types, index values, first and last five rows is displayed. The describe() function is used to provide a quick statistical overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Country/Region', 'Province/State', 'Lat', 'Long', 'Confirmed',\n",
      "       'Recovered', 'Deaths'],\n",
      "      dtype='object')\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# The names of the columns\n",
    "\n",
    "columns_dataset = preprocessing_dataset.columns\n",
    "print(columns_dataset)\n",
    "print(len(columns_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year             int64\n",
      "Mo             float64\n",
      "Dy             float64\n",
      "Hr             float64\n",
      "Mn             float64\n",
      "Sec            float64\n",
      "Tsu             object\n",
      "Vol             object\n",
      "Addl            object\n",
      "Name            object\n",
      "Latitude       float64\n",
      "Longitude      float64\n",
      "Focal          float64\n",
      "Mag            float64\n",
      "MMI Int        float64\n",
      "Num            float64\n",
      "De             float64\n",
      "Num.1          float64\n",
      "De.1           float64\n",
      "$Mill          float64\n",
      "De.2           float64\n",
      "Num.2          float64\n",
      "De.3           float64\n",
      "Num.3          float64\n",
      "De.4           float64\n",
      "Unnamed: 25    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The data type of each column\n",
    "\n",
    "print(preprocessing_dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 23493, 23494, 23495], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, the indexes associated with the dataframe are checked\n",
    "\n",
    "preprocessing_dataset.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top five and bottom five rows are displayed below. It is seen that each observation forms a row, is defined by an index, and attributes of those observations are displayed in the columns of the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Country/Region Province/State   Lat  Long  Confirmed  Recovered  \\\n",
      "0  2020-01-22    Afghanistan            NaN  33.0  65.0        0.0        0.0   \n",
      "1  2020-01-23    Afghanistan            NaN  33.0  65.0        0.0        0.0   \n",
      "2  2020-01-24    Afghanistan            NaN  33.0  65.0        0.0        0.0   \n",
      "3  2020-01-25    Afghanistan            NaN  33.0  65.0        0.0        0.0   \n",
      "4  2020-01-26    Afghanistan            NaN  33.0  65.0        0.0        0.0   \n",
      "\n",
      "   Deaths  \n",
      "0     0.0  \n",
      "1     0.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     0.0  \n"
     ]
    }
   ],
   "source": [
    "# First five rows\n",
    "\n",
    "print(preprocessing_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Country/Region Province/State   Lat  Long  Confirmed  \\\n",
      "23491  2020-04-15       Zimbabwe            NaN -20.0  30.0       23.0   \n",
      "23492  2020-04-16       Zimbabwe            NaN -20.0  30.0       23.0   \n",
      "23493  2020-04-17       Zimbabwe            NaN -20.0  30.0       24.0   \n",
      "23494  2020-04-18       Zimbabwe            NaN -20.0  30.0       25.0   \n",
      "23495  2020-04-19       Zimbabwe            NaN -20.0  30.0       25.0   \n",
      "\n",
      "       Recovered  Deaths  \n",
      "23491        1.0     3.0  \n",
      "23492        1.0     3.0  \n",
      "23493        2.0     3.0  \n",
      "23494        2.0     3.0  \n",
      "23495        2.0     3.0  \n"
     ]
    }
   ],
   "source": [
    "# Last five rows\n",
    "\n",
    "print(preprocessing_dataset.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Year           Mo           Dy           Hr          Mn  \\\n",
      "count   6144.000000  5739.000000  5587.000000  4113.000000  3908.00000   \n",
      "unique          NaN          NaN          NaN          NaN         NaN   \n",
      "top             NaN          NaN          NaN          NaN         NaN   \n",
      "freq            NaN          NaN          NaN          NaN         NaN   \n",
      "mean    1804.691243     6.505663    15.721675    11.304644    28.86131   \n",
      "std      376.404999     3.449445     8.749653     7.032811    17.14624   \n",
      "min    -2150.000000     1.000000     1.000000     0.000000     0.00000   \n",
      "25%     1820.000000     4.000000     8.000000     5.000000    14.75000   \n",
      "50%     1928.000000     7.000000    16.000000    11.000000    30.00000   \n",
      "75%     1988.000000     9.000000    23.000000    17.000000    44.00000   \n",
      "max     2019.000000    12.000000    31.000000    23.000000    59.00000   \n",
      "\n",
      "                Sec   Tsu  Vol  Addl                    Name  ...  \\\n",
      "count   2791.000000  1853   64  6144                    6143  ...   \n",
      "unique          NaN     1    1     1                    3790  ...   \n",
      "top             NaN   Tsu  Vol     *  CHINA: YUNNAN PROVINCE  ...   \n",
      "freq            NaN  1853   64  6144                      79  ...   \n",
      "mean      29.663633   NaN  NaN   NaN                     NaN  ...   \n",
      "std       17.176807   NaN  NaN   NaN                     NaN  ...   \n",
      "min        0.100000   NaN  NaN   NaN                     NaN  ...   \n",
      "25%       14.550000   NaN  NaN   NaN                     NaN  ...   \n",
      "50%       29.400000   NaN  NaN   NaN                     NaN  ...   \n",
      "75%       44.450000   NaN  NaN   NaN                     NaN  ...   \n",
      "max       59.900000   NaN  NaN   NaN                     NaN  ...   \n",
      "\n",
      "                 De          Num.1         De.1          $Mill         De.2  \\\n",
      "count   2510.000000    1212.000000  1397.000000     496.000000  4387.000000   \n",
      "unique          NaN            NaN          NaN            NaN          NaN   \n",
      "top             NaN            NaN          NaN            NaN          NaN   \n",
      "freq            NaN            NaN          NaN            NaN          NaN   \n",
      "mean       2.019124    2215.919142     1.957767    1245.874780     2.265785   \n",
      "std        1.156726   26612.926726     1.080734    6820.271167     0.955949   \n",
      "min        0.000000       1.000000     1.000000       0.013000     1.000000   \n",
      "25%        1.000000      10.000000     1.000000       3.850000     1.000000   \n",
      "50%        1.000000      40.000000     1.000000      21.400000     2.000000   \n",
      "75%        3.000000     200.000000     3.000000     196.250000     3.000000   \n",
      "max        4.000000  799000.000000     4.000000  100000.000000     4.000000   \n",
      "\n",
      "               Num.2         De.3         Num.3        De.4  Unnamed: 25  \n",
      "count   7.690000e+02  1669.000000  4.690000e+02  894.000000    61.000000  \n",
      "unique           NaN          NaN           NaN         NaN          NaN  \n",
      "top              NaN          NaN           NaN         NaN          NaN  \n",
      "freq             NaN          NaN           NaN         NaN          NaN  \n",
      "mean    1.785742e+04     2.689635  2.564698e+04    2.517897    11.754098  \n",
      "std     1.993090e+05     1.058037  2.550184e+05    1.122514    12.492205  \n",
      "min     1.000000e+00     0.000000  1.000000e+00    1.000000     1.000000  \n",
      "25%     6.500000e+01     2.000000  8.700000e+01    1.000000     2.000000  \n",
      "50%     5.120000e+02     3.000000  6.140000e+02    3.000000     7.000000  \n",
      "75%     4.000000e+03     3.000000  3.487000e+03    3.000000    20.000000  \n",
      "max     5.360000e+06     4.000000  5.360000e+06    4.000000    54.000000  \n",
      "\n",
      "[11 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# The basic statistical overview of the dataset is provided using Pandas describe()\n",
    "\n",
    "print(preprocessing_dataset.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Addressing Missing Values\n",
    "\n",
    "The missing values in *Name, Country/Region, Province/State, Latitude, Longitude, Confirmed, Recovered, Deaths are explored in detail. A question mark(?) is used to replace the missing values in other variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                  0\n",
      "Country/Region        0\n",
      "Province/State    16198\n",
      "Lat                   0\n",
      "Long                  0\n",
      "Confirmed            89\n",
      "Recovered          1246\n",
      "Deaths               89\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The null values in the dataset is viewed: \n",
    "\n",
    "print(preprocessing_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Province/State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists 16198 missing entries in *Province/State*. The rows containing missing values is retrieved. Based on the latitude and longitude of mentioned in that row, the entire dataset is searched to find a similar entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 23493, 23494, 23495], dtype=int64),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing index of the missing entries in the Name column\n",
    "\n",
    "np.where(pd.isnull(preprocessing_dataset['Province/State']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Country/Region Province/State   Lat  Long Confirmed  \\\n",
      "0      2020-01-22    Afghanistan              ?  33.0  65.0         0   \n",
      "1      2020-01-23    Afghanistan              ?  33.0  65.0         0   \n",
      "2      2020-01-24    Afghanistan              ?  33.0  65.0         0   \n",
      "3      2020-01-25    Afghanistan              ?  33.0  65.0         0   \n",
      "4      2020-01-26    Afghanistan              ?  33.0  65.0         0   \n",
      "...           ...            ...            ...   ...   ...       ...   \n",
      "23491  2020-04-15       Zimbabwe              ? -20.0  30.0        23   \n",
      "23492  2020-04-16       Zimbabwe              ? -20.0  30.0        23   \n",
      "23493  2020-04-17       Zimbabwe              ? -20.0  30.0        24   \n",
      "23494  2020-04-18       Zimbabwe              ? -20.0  30.0        25   \n",
      "23495  2020-04-19       Zimbabwe              ? -20.0  30.0        25   \n",
      "\n",
      "      Recovered Deaths  \n",
      "0             0      0  \n",
      "1             0      0  \n",
      "2             0      0  \n",
      "3             0      0  \n",
      "4             0      0  \n",
      "...         ...    ...  \n",
      "23491         1      3  \n",
      "23492         1      3  \n",
      "23493         2      3  \n",
      "23494         2      3  \n",
      "23495         2      3  \n",
      "\n",
      "[23496 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "preprocessing_dataset = preprocessing_dataset.fillna('?')\n",
    "print(preprocessing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Verifying if the null value still exists\n",
    "\n",
    "print(preprocessing_dataset['Province/State'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Confirmed, Recovered and Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the total number of missing values for Column Confirmed\n",
    "\n",
    "print(preprocessing_dataset.Confirmed.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the total number of missing Recovered\n",
    "\n",
    "print(preprocessing_dataset.Recovered.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the total number of missing Deaths\n",
    "\n",
    "print(preprocessing_dataset.Deaths.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reasons behind the missing values is not yet understood.The COVID-19 is an ongoing, extraordinary situation, and the numbers are being updated regularly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Other variables\n",
    "\n",
    "Not enough is known about the missing values in other variables. These empty entries are replaced with a question mark(?) for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              0\n",
       "Country/Region    0\n",
       "Province/State    0\n",
       "Lat               0\n",
       "Long              0\n",
       "Confirmed         0\n",
       "Recovered         0\n",
       "Deaths            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the number of missing values in the dataset\n",
    "\n",
    "preprocessing_dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date Country/Region Province/State   Lat  Long Confirmed  \\\n",
      "0      2020-01-22    Afghanistan              ?  33.0  65.0         0   \n",
      "1      2020-01-23    Afghanistan              ?  33.0  65.0         0   \n",
      "2      2020-01-24    Afghanistan              ?  33.0  65.0         0   \n",
      "3      2020-01-25    Afghanistan              ?  33.0  65.0         0   \n",
      "4      2020-01-26    Afghanistan              ?  33.0  65.0         0   \n",
      "...           ...            ...            ...   ...   ...       ...   \n",
      "23491  2020-04-15       Zimbabwe              ? -20.0  30.0        23   \n",
      "23492  2020-04-16       Zimbabwe              ? -20.0  30.0        23   \n",
      "23493  2020-04-17       Zimbabwe              ? -20.0  30.0        24   \n",
      "23494  2020-04-18       Zimbabwe              ? -20.0  30.0        25   \n",
      "23495  2020-04-19       Zimbabwe              ? -20.0  30.0        25   \n",
      "\n",
      "      Recovered Deaths  \n",
      "0             0      0  \n",
      "1             0      0  \n",
      "2             0      0  \n",
      "3             0      0  \n",
      "4             0      0  \n",
      "...         ...    ...  \n",
      "23491         1      3  \n",
      "23492         1      3  \n",
      "23493         2      3  \n",
      "23494         2      3  \n",
      "23495         2      3  \n",
      "\n",
      "[23496 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replacing the missing values with a question mark(?)\n",
    "\n",
    "preprocessing_dataset = preprocessing_dataset.fillna('?')\n",
    "print(preprocessing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              0\n",
      "Country/Region    0\n",
      "Province/State    0\n",
      "Lat               0\n",
      "Long              0\n",
      "Confirmed         0\n",
      "Recovered         0\n",
      "Deaths            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verifying that there are no missing values present in the entire dataset\n",
    "\n",
    "print(preprocessing_dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Filtering required columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 08 columns, Country, Latitude, Longitude, Confirmed, Recovered, and Deaths is thought to be not relevant for most of the analysis. They are referred to later when comparing the events. For the rest of the analysis, only the following columns are filtered: \n",
    "\n",
    "Country, Province, Latitude, Longitude, Confirmed, Recovered, and Deaths. The code for filtering these columns is displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country/Region Province/State   Lat  Long Confirmed Recovered Deaths\n",
      "0        Afghanistan              ?  33.0  65.0         0         0      0\n",
      "1        Afghanistan              ?  33.0  65.0         0         0      0\n",
      "2        Afghanistan              ?  33.0  65.0         0         0      0\n",
      "3        Afghanistan              ?  33.0  65.0         0         0      0\n",
      "4        Afghanistan              ?  33.0  65.0         0         0      0\n",
      "...              ...            ...   ...   ...       ...       ...    ...\n",
      "23491       Zimbabwe              ? -20.0  30.0        23         1      3\n",
      "23492       Zimbabwe              ? -20.0  30.0        23         1      3\n",
      "23493       Zimbabwe              ? -20.0  30.0        24         2      3\n",
      "23494       Zimbabwe              ? -20.0  30.0        25         2      3\n",
      "23495       Zimbabwe              ? -20.0  30.0        25         2      3\n",
      "\n",
      "[23496 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_for_analysis = preprocessing_dataset.filter(['Country/Region', 'Province/State', 'Lat', 'Long', 'Confirmed', 'Recovered', 'Deaths'])\n",
    "print(dataset_for_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date: Date on which a case was reported\n",
    "Country/Region: Name of the country/region\n",
    "Province/State: Name of the Province/State\n",
    "Lat: Latitude\n",
    "Long: Longitude\n",
    "Confirmed: Positive cases\n",
    "Recovered: Number of cases where people who have tested positive have recovered\n",
    "Deaths: Total number of deaths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Downloading preprocessed dataset as a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads the preprocessed dataset as a csv file onto the local system. The downloaded file is then used for further analysis from here on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_for_analysis.to_csv('Dataset For Analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of the dataset\n",
    "\n",
    "    1. The dataset consists of 23496 rows and 08 columns.\n",
    "\n",
    "### Addressing missing values\n",
    "\n",
    "    1. There exist 16198 missing values in Province/State column, 89 in Confirmed, 1245 in Recovered, and 98 in Deaths. \n",
    "    2. The database was updated accordingly and verified to make sure the null value was updated.\n",
    "    3. The reasons behind the missing values in other variables is not well understood and is replaced with a '?'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
